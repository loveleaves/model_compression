{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NNI量化实践\n",
    "\n",
    "量化通过减少表示权重或激活所需的位数来减小模型大小并加快推理时间。在 NNI 中，支持训练后量化算法和量化感知训练算法。本节使用训练后量化算法为例来展示NNI中量化的用法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 参考文档：https://nni.readthedocs.io/zh/stable/tutorials/quantization_quick_start.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.optim import *\n",
    "from torch.optim.lr_scheduler import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import *\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe3b715c670>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置归一化\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# 获取数据集\n",
    "train_dataset = datasets.MNIST(root='../../ch02/data/mnist', train=True, download=True, transform=transform)  \n",
    "test_dataset = datasets.MNIST(root='../../ch02/data/mnist', train=False, download=True, transform=transform)  # train=True训练集，=False测试集\n",
    "total_test_samples = len(test_dataset)\n",
    "# 设置DataLoader\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个LeNet网络\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(in_features=16 * 4 * 4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=num_classes)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(self.relu1(self.conv1(x)))\n",
    "        x = self.maxpool(self.relu2(self.conv2(x)))\n",
    "\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "model = LeNet().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(batch, model):\n",
    "    x, y = batch[0].to(device), batch[1].to(device)\n",
    "    logits = model(x)\n",
    "    criterion = nn.CrossEntropyLoss() \n",
    "    loss = criterion(logits, y)\n",
    "    return loss\n",
    "\n",
    "def training_model(model: torch.nn.Module, optimizer, training_step, scheduler,\n",
    "                   max_steps, max_epochs):\n",
    "    model.train()\n",
    "    max_epochs = max_epochs if max_epochs else 1 if max_steps is None else 100\n",
    "    current_steps = 0\n",
    "\n",
    "    # training\n",
    "    for epoch in range(max_epochs):\n",
    "        print(f'Epoch {epoch} start!')\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = training_step(batch, model)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            current_steps += 1\n",
    "            if max_steps and current_steps == max_steps:\n",
    "                return\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluating_model(model: torch.nn.Module):\n",
    "    model.eval()\n",
    "    # testing\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct += preds.eq(y.view_as(preds)).sum().item()\n",
    "    return correct / total_test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 start!\n",
      "Epoch 1 start!\n",
      "Epoch 2 start!\n",
      "Epoch 3 start!\n",
      "Epoch 4 start!\n",
      "pure training 5 epochs: 110.96141934394836s\n",
      "pure evaluating: 1.8336389064788818s    Acc.: 0.9895\n"
     ]
    }
   ],
   "source": [
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "start = time.time()\n",
    "training_model(model, optimizer, training_step, None, None, 5)\n",
    "print(f'pure training 5 epochs: {time.time() - start}s')\n",
    "start = time.time()\n",
    "acc = evaluating_model(model)\n",
    "print(f'pure evaluating: {time.time() - start}s    Acc.: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型量化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 start!\n",
      "Epoch 1 start!\n",
      "Epoch 2 start!\n",
      "Epoch 3 start!\n",
      "Epoch 4 start!\n",
      "pure training 5 epochs: 101.41740226745605s\n",
      "defaultdict(<class 'dict'>, {'fc1': {'weight': {'scale': tensor(0.0021), 'zero_point': tensor(22.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(0.2163), 'tracked_min': tensor(-0.3066)}, '_input_0': {'scale': tensor(0.0655), 'zero_point': tensor(-127.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(16.6477), 'tracked_min': tensor(0.)}, '_output_0': {'scale': tensor(0.1609), 'zero_point': tensor(7.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(19.3163), 'tracked_min': tensor(-21.5482)}}, 'conv2': {'weight': {'scale': tensor(0.0033), 'zero_point': tensor(-15.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(0.4663), 'tracked_min': tensor(-0.3678)}, '_input_0': {'scale': tensor(0.0432), 'zero_point': tensor(-127.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(10.9718), 'tracked_min': tensor(0.)}, '_output_0': {'scale': tensor(0.1722), 'zero_point': tensor(10.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(20.1352), 'tracked_min': tensor(-23.6116)}}, 'fc2': {'weight': {'scale': tensor(0.0018), 'zero_point': tensor(-16.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(0.2528), 'tracked_min': tensor(-0.1970)}, '_input_0': {'scale': tensor(0.0586), 'zero_point': tensor(-127.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(14.8847), 'tracked_min': tensor(0.)}, '_output_0': {'scale': tensor(0.0893), 'zero_point': tensor(-31.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(14.0773), 'tracked_min': tensor(-8.6157)}}, 'conv1': {'weight': {'scale': tensor(0.0047), 'zero_point': tensor(-20.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(0.6953), 'tracked_min': tensor(-0.5063)}, '_input_0': {'scale': tensor(0.0128), 'zero_point': tensor(-94.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(2.8215), 'tracked_min': tensor(-0.4242)}, '_output_0': {'scale': tensor(0.0797), 'zero_point': tensor(-12.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(11.0536), 'tracked_min': tensor(-9.1925)}}, 'relu1': {'_output_0': {'scale': tensor(0.0585), 'zero_point': tensor(-127.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(14.8716), 'tracked_min': tensor(0.)}}, 'relu2': {'_output_0': {'scale': tensor(0.0654), 'zero_point': tensor(-127.), 'quant_dtype': 'int8', 'quant_scheme': 'affine', 'quant_bits': 8, 'tracked_max': tensor(16.6008), 'tracked_min': tensor(0.)}}})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02daa77b348f493d8555b8a6e5f0d04e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantization evaluating: 1.7575781345367432s    Acc.: 0.9851\n"
     ]
    }
   ],
   "source": [
    "import nni\n",
    "from nni.compression.quantization import QATQuantizer\n",
    "from nni.compression.utils import TorchEvaluator\n",
    "\n",
    "\n",
    "optimizer = nni.trace(SGD)(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "evaluator = TorchEvaluator(training_model, optimizer, training_step) \n",
    "\n",
    "# 将conv、fc、relu层量化为int8\n",
    "config_list = [{\n",
    "    'op_names': ['conv1', 'conv2', 'fc1', 'fc2'],\n",
    "    'target_names': ['_input_', 'weight', '_output_'],\n",
    "    'quant_dtype': 'int8',\n",
    "    'quant_scheme': 'affine',\n",
    "    'granularity': 'default',\n",
    "},{\n",
    "    'op_names': ['relu1', 'relu2'],\n",
    "    'target_names': ['_output_'],\n",
    "    'quant_dtype': 'int8',\n",
    "    'quant_scheme': 'affine',\n",
    "    'granularity': 'default',\n",
    "}]\n",
    "\n",
    "quantizer = QATQuantizer(model, config_list, evaluator, len(train_loader))\n",
    "real_input = next(iter(train_loader))[0].to(device)\n",
    "quantizer.track_forward(real_input)\n",
    "\n",
    "start = time.time()\n",
    "_, calibration_config = quantizer.compress(None, max_epochs=5)\n",
    "print(f'pure training 5 epochs: {time.time() - start}s')\n",
    "\n",
    "print(calibration_config)\n",
    "start = time.time()\n",
    "acc = evaluating_model(model)\n",
    "print(f'quantization evaluating: {time.time() - start}s    Acc.: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 量化后虽然训练需要的时间增加了，但推理的时间减少了"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "distill",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
