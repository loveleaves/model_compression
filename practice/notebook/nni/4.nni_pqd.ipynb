{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用NNI对模型进行剪枝、量化、蒸馏压缩\n",
    "本节使用NNI框架对Resnet18模型进行融合压缩（剪枝、量化、蒸馏），数据集使用Cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">参考链接：https://github.com/microsoft/nni/blob/master/examples/compression/fusion/pqd_fuse.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import torch\n",
    "\n",
    "from models import (\n",
    "    build_resnet18,\n",
    "    prepare_dataloader,\n",
    "    prepare_optimizer,\n",
    "    train,\n",
    "    training_step,\n",
    "    evaluate,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nni.compression import TorchEvaluator\n",
    "from nni.compression.base.compressor import Quantizer\n",
    "from nni.compression.distillation import DynamicLayerwiseDistiller\n",
    "from nni.compression.pruning import TaylorPruner, AGPPruner\n",
    "from nni.compression.quantization import QATQuantizer\n",
    "from nni.compression.utils import auto_set_denpendency_group_ids\n",
    "from nni.compression.speedup import ModelSpeedup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Resnet18模型，数据集使用Cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Original model paramater number:  11181642\n",
      "Original model acc:  12.24 %\n"
     ]
    }
   ],
   "source": [
    "#  Resnet18 on Cifar10\n",
    "model = build_resnet18()\n",
    "_, test_loader = prepare_dataloader()\n",
    "print('Original model paramater number: ', sum([param.numel() for param in model.parameters()]))\n",
    "print('Original model acc: ', evaluate(model, test_loader), '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 微调Resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "[Training Epoch 0 / Step 391] Final Acc: 71.12%\n",
      "[Training Epoch 1 / Step 782] Final Acc: 52.1%\n",
      "[Training Epoch 2 / Step 1173] Final Acc: 70.93%\n",
      "[Training Epoch 3 / Step 1564] Final Acc: 73.81%\n",
      "[Training Epoch 4 / Step 1955] Final Acc: 77.49%\n",
      "[Training Epoch 5 / Step 2346] Final Acc: 78.85%\n",
      "[Training Epoch 6 / Step 2737] Final Acc: 79.18%\n",
      "[Training Epoch 7 / Step 3128] Final Acc: 79.7%\n",
      "[Training Epoch 8 / Step 3519] Final Acc: 81.5%\n",
      "[Training Epoch 9 / Step 3910] Final Acc: 80.98%\n",
      "[Training Epoch 10 / Step 4301] Final Acc: 81.38%\n",
      "[Training Epoch 11 / Step 4692] Final Acc: 82.42%\n",
      "[Training Epoch 12 / Step 5083] Final Acc: 81.52%\n",
      "[Training Epoch 13 / Step 5474] Final Acc: 81.56%\n",
      "[Training Epoch 14 / Step 5865] Final Acc: 81.85%\n",
      "[Training Epoch 15 / Step 6256] Final Acc: 82.57%\n",
      "[Training Epoch 16 / Step 6647] Final Acc: 83.29%\n",
      "[Training Epoch 17 / Step 7038] Final Acc: 83.21%\n",
      "[Training Epoch 18 / Step 7429] Final Acc: 83.47%\n",
      "[Training Epoch 19 / Step 7820] Final Acc: 83.91%\n",
      "[Training Epoch 20 / Step 8211] Final Acc: 82.96%\n",
      "[Training Epoch 21 / Step 8602] Final Acc: 82.5%\n",
      "[Training Epoch 22 / Step 8993] Final Acc: 82.85%\n",
      "[Training Epoch 23 / Step 9384] Final Acc: 83.8%\n",
      "[Training Epoch 24 / Step 9775] Final Acc: 83.61%\n",
      "[Training Epoch 25 / Step 10166] Final Acc: 84.43%\n",
      "[Training Epoch 26 / Step 10557] Final Acc: 84.34%\n",
      "[Training Epoch 27 / Step 10948] Final Acc: 84.33%\n",
      "[Training Epoch 28 / Step 11339] Final Acc: 83.8%\n",
      "[Training Epoch 29 / Step 11730] Final Acc: 83.59%\n",
      "Original model paramater number:  11181642\n",
      "Original model after 10 epochs finetuning acc:  83.59 %\n"
     ]
    }
   ],
   "source": [
    "optimizer = prepare_optimizer(model)\n",
    "train(model, optimizer, training_step, lr_scheduler=None, max_steps=None, max_epochs=30)\n",
    "print('Original model paramater number: ', sum([param.numel() for param in model.parameters()]))\n",
    "print('Original model after 30 epochs finetuning acc: ', evaluate(model, test_loader), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一个与学生模型相同的教师模型，并复制微调后的学生模型的权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a teacher model\n",
    "teacher_model = build_resnet18()\n",
    "teacher_model.load_state_dict(pickle.loads(pickle.dumps(model.state_dict())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 剪枝\n",
    "\n",
    "为模型中所有 Conv2d 层设置剪枝，指定稀疏率为 0.5，并为 BatchNorm2d 层设置相应的目标对齐策略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pruner\n",
    "bn_list = [module_name for module_name, module in model.named_modules() if isinstance(module, torch.nn.BatchNorm2d)]\n",
    "p_config_list = [{\n",
    "    'op_types': ['Conv2d'],\n",
    "    'sparse_ratio': 0.5\n",
    "}, *[{\n",
    "    'op_names': [name],\n",
    "    'target_names': ['_output_'],\n",
    "    'target_settings': {\n",
    "        '_output_': {\n",
    "            'align': {\n",
    "                'module_name': name.replace('bn', 'conv') if 'bn' in name else name.replace('downsample.1', 'downsample.0'),\n",
    "                'target_name': 'weight',\n",
    "                'dims': [0],\n",
    "            },\n",
    "            'granularity': 'per_channel'\n",
    "        }\n",
    "    }\n",
    "} for name in bn_list]]\n",
    "dummy_input = torch.rand(8, 3, 224, 224).to(device)\n",
    "p_config_list = auto_set_denpendency_group_ids(model, p_config_list, dummy_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化优化器和评估器，并使用 TaylorPruner 和 AGPPruner 进行剪枝。TaylorPruner 使用泰勒展开法计算权重的重要性，AGPPruner 是一种渐进式剪枝方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = prepare_optimizer(model)\n",
    "evaluator = TorchEvaluator(train, optimizer, training_step)\n",
    "sub_pruner = TaylorPruner(model, p_config_list, evaluator, training_steps=100)\n",
    "scheduled_pruner = AGPPruner(sub_pruner, interval_steps=100, total_times=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 量化\n",
    "\n",
    "使用 QATQuantizer 创建量化器，对 Conv2d 和 BatchNorm2d 层进行量化，采用 int8 精度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create quantizer\n",
    "q_config_list = [{\n",
    "    'op_types': ['Conv2d'],\n",
    "    'quant_dtype': 'int8',\n",
    "    'target_names': ['_input_'],\n",
    "    'granularity': 'per_channel'\n",
    "}, {\n",
    "    'op_types': ['Conv2d'],\n",
    "    'quant_dtype': 'int8',\n",
    "    'target_names': ['weight'],\n",
    "    'granularity': 'out_channel'\n",
    "}, {\n",
    "    'op_types': ['BatchNorm2d'],\n",
    "    'quant_dtype': 'int8',\n",
    "    'target_names': ['_output_'],\n",
    "    'granularity': 'per_channel'\n",
    "}]\n",
    "\n",
    "quantizer = QATQuantizer.from_compressor(scheduled_pruner, q_config_list, quant_start_step=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 蒸馏\n",
    "定义 teacher_predict 函数用于从教师模型生成预测，并创建 DynamicLayerwiseDistiller 进行逐层蒸馏。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "[Training Epoch 0 / Step 391] Final Acc: 80.23%\n",
      "[Training Epoch 1 / Step 782] Final Acc: 79.04%\n",
      "[Training Epoch 2 / Step 1173] Final Acc: 78.22%\n",
      "[Training Epoch 3 / Step 1564] Final Acc: 78.4%\n",
      "[Training Epoch 4 / Step 1955] Final Acc: 78.97%\n",
      "[Training Epoch 5 / Step 2346] Final Acc: 79.02%\n",
      "[Training Epoch 6 / Step 2737] Final Acc: 78.42%\n",
      "[Training Epoch 7 / Step 3128] Final Acc: 79.56%\n",
      "[Training Epoch 8 / Step 3519] Final Acc: 78.64%\n",
      "[Training Epoch 9 / Step 3910] Final Acc: 79.56%\n",
      "[Training Epoch 10 / Step 4301] Final Acc: 79.06%\n",
      "[Training Epoch 11 / Step 4692] Final Acc: 79.5%\n",
      "[Training Epoch 12 / Step 5083] Final Acc: 79.39%\n",
      "[Training Epoch 13 / Step 5474] Final Acc: 80.31%\n",
      "[Training Epoch 14 / Step 5865] Final Acc: 79.6%\n",
      "[Training Epoch 15 / Step 6000] Final Acc: 80.44%\n"
     ]
    }
   ],
   "source": [
    "# create distiller\n",
    "def teacher_predict(batch, teacher_model):\n",
    "    return teacher_model(batch[0])\n",
    "\n",
    "d_config_list = [{\n",
    "    'op_types': ['Conv2d'],\n",
    "    'lambda': 0.1,\n",
    "    'apply_method': 'mse',\n",
    "}]\n",
    "distiller = DynamicLayerwiseDistiller.from_compressor(quantizer, d_config_list, teacher_model, teacher_predict, 0.1)\n",
    "\n",
    "# max_steps contains (30 iterations 100 steps agp taylor pruning, and 3000 steps finetuning)\n",
    "distiller.compress(max_steps=100 * 60, max_epochs=None)\n",
    "distiller.unwrap_model()\n",
    "distiller.unwrap_teacher_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加速模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-23 17:38:35] \u001b[32mStart to speedup the model...\u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mResolve the mask conflict before mask propagate...\u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mdim0 sparsity: 0.500000\u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mdim1 sparsity: 0.000000\u001b[0m\n",
      "0 Filter\n",
      "[2024-09-23 17:38:35] \u001b[32mdim0 sparsity: 0.500000\u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mdim1 sparsity: 0.000000\u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mInfer module masks...\u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate original variables\u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for placeholder: x, output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: conv1, weight:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: bn1, _output_0:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: relu, , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: maxpool, , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer1_0_conv1, weight:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer1_0_bn1, _output_0:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer1_0_relu, , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer1_0_conv2, weight:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer1_0_bn2, _output_0:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_function: iadd, output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer1_0_relu_1, , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer1_1_conv1, weight:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer1_1_bn1, _output_0:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer1_1_relu, , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer1_1_conv2, weight:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer1_1_bn2, _output_0:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_function: iadd_1, output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer1_1_relu_1, , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer2_0_conv1, weight:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer2_0_bn1, _output_0:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer2_0_relu, , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer2_0_conv2, weight:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer2_0_bn2, _output_0:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer2_0_downsample_0, weight:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer2_0_downsample_1, _output_0:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_function: iadd_2, output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer2_0_relu_1, , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer2_1_conv1, weight:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer2_1_bn1, _output_0:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer2_1_relu, , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer2_1_conv2, weight:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer2_1_bn2, _output_0:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_function: iadd_3, output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer2_1_relu_1, , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer3_0_conv1, weight:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer3_0_bn1, _output_0:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer3_0_relu, , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer3_0_conv2, weight:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer3_0_bn2, _output_0:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer3_0_downsample_0, weight:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer3_0_downsample_1, _output_0:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_function: iadd_4, output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer3_0_relu_1, , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer3_1_conv1, weight:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer3_1_bn1, _output_0:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer3_1_relu, , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer3_1_conv2, weight:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer3_1_bn2, _output_0:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_function: iadd_5, output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer3_1_relu_1, , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer4_0_conv1, weight:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer4_0_bn1, _output_0:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer4_0_relu, , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer4_0_conv2, weight:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer4_0_bn2, _output_0:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer4_0_downsample_0, weight:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer4_0_downsample_1, _output_0:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_function: iadd_6, output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer4_0_relu_1, , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer4_1_conv1, weight:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer4_1_bn1, _output_0:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer4_1_relu, , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer4_1_conv2, weight:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer4_1_bn2, _output_0:  0.5000 , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_function: iadd_7, output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: layer4_1_relu_1, , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: avgpool, , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_function: flatten, output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for call_module: fc, , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mPropagate variables for output: output, output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct sparsity...\u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for placeholder: x, output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: conv1, weight:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: bn1, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: relu, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: maxpool, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer1_0_conv1, weight:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer1_0_bn1, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer1_0_relu, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer1_0_conv2, weight:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer1_0_bn2, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_function: iadd, output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer1_0_relu_1, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer1_1_conv1, weight:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer1_1_bn1, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer1_1_relu, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer1_1_conv2, weight:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer1_1_bn2, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_function: iadd_1, output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer1_1_relu_1, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer2_0_conv1, weight:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer2_0_bn1, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer2_0_relu, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer2_0_conv2, weight:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer2_0_bn2, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer2_0_downsample_0, weight:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer2_0_downsample_1, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_function: iadd_2, output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer2_0_relu_1, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer2_1_conv1, weight:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer2_1_bn1, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer2_1_relu, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer2_1_conv2, weight:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer2_1_bn2, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_function: iadd_3, output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer2_1_relu_1, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer3_0_conv1, weight:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer3_0_bn1, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer3_0_relu, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer3_0_conv2, weight:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer3_0_bn2, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer3_0_downsample_0, weight:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer3_0_downsample_1, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_function: iadd_4, output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer3_0_relu_1, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer3_1_conv1, weight:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer3_1_bn1, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer3_1_relu, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer3_1_conv2, weight:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer3_1_bn2, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_function: iadd_5, output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer3_1_relu_1, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer4_0_conv1, weight:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer4_0_bn1, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer4_0_relu, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer4_0_conv2, weight:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer4_0_bn2, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer4_0_downsample_0, weight:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer4_0_downsample_1, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_function: iadd_6, output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer4_0_relu_1, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer4_1_conv1, weight:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer4_1_bn1, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer4_1_relu, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer4_1_conv2, weight:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer4_1_bn2, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_function: iadd_7, output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: layer4_1_relu_1, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: avgpool, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_function: flatten, output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for call_module: fc, , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate direct mask for output: output, output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect sparsity...\u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for output: output, output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: fc, , output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_function: flatten, output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: avgpool, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer4_1_relu_1, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_function: iadd_7, output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer4_1_bn2, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer4_1_conv2, weight:  0.7500 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer4_1_relu, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer4_1_bn1, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer4_1_conv1, weight:  0.7500 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer4_0_relu_1, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_function: iadd_6, output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer4_0_downsample_1, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer4_0_downsample_0, weight:  0.7500 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer4_0_bn2, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer4_0_conv2, weight:  0.7500 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer4_0_relu, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer4_0_bn1, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer4_0_conv1, weight:  0.7500 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer3_1_relu_1, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_function: iadd_5, output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer3_1_bn2, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer3_1_conv2, weight:  0.7500 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer3_1_relu, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer3_1_bn1, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer3_1_conv1, weight:  0.7500 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer3_0_relu_1, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_function: iadd_4, output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer3_0_downsample_1, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer3_0_downsample_0, weight:  0.7500 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer3_0_bn2, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer3_0_conv2, weight:  0.7500 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer3_0_relu, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer3_0_bn1, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer3_0_conv1, weight:  0.7500 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer2_1_relu_1, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_function: iadd_3, output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer2_1_bn2, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer2_1_conv2, weight:  0.7500 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer2_1_relu, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer2_1_bn1, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer2_1_conv1, weight:  0.7500 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer2_0_relu_1, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_function: iadd_2, output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer2_0_downsample_1, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer2_0_downsample_0, weight:  0.7500 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer2_0_bn2, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer2_0_conv2, weight:  0.7500 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer2_0_relu, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer2_0_bn1, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer2_0_conv1, weight:  0.7500 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_module: layer1_1_relu_1, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:35] \u001b[32mUpdate indirect mask for call_function: iadd_1, output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mUpdate indirect mask for call_module: layer1_1_bn2, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mUpdate indirect mask for call_module: layer1_1_conv2, weight:  0.7500 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mUpdate indirect mask for call_module: layer1_1_relu, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mUpdate indirect mask for call_module: layer1_1_bn1, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mUpdate indirect mask for call_module: layer1_1_conv1, weight:  0.7500 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mUpdate indirect mask for call_module: layer1_0_relu_1, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mUpdate indirect mask for call_function: iadd, output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mUpdate indirect mask for call_module: layer1_0_bn2, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mUpdate indirect mask for call_module: layer1_0_conv2, weight:  0.7500 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mUpdate indirect mask for call_module: layer1_0_relu, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mUpdate indirect mask for call_module: layer1_0_bn1, _output_0:  0.5000 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mUpdate indirect mask for call_module: layer1_0_conv1, weight:  0.7500 , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mUpdate indirect mask for call_module: maxpool, , output mask:  0.5000 \u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mUpdate indirect mask for call_module: relu, , output mask:  0.6316 \u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mUpdate indirect mask for call_module: bn1, _output_0:  0.5000 , output mask:  0.6316 \u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mUpdate indirect mask for call_module: conv1, weight:  0.5000 , output mask:  0.6316 \u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mUpdate indirect mask for placeholder: x, output mask:  0.0000 \u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mResolve the mask conflict after mask propagate...\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mdim0 sparsity: 0.500000\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mdim1 sparsity: 0.499610\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[33mWARNING: both dim0 and dim1 masks found.\u001b[0m\n",
      "0 Filter\n",
      "[2024-09-23 17:38:36] \u001b[32mFine-grained mask detected\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mFine-grained mask detected\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mFine-grained mask detected\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mFine-grained mask detected\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mdim0 sparsity: 0.500000\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mdim1 sparsity: 0.191517\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[33mWARNING: both dim0 and dim1 masks found.\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mReplace compressed modules...\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace conv2d with in_channels: 3, out_channels: 32\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: bn1, op_type: BatchNorm2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace batchnorm2d with num_features: 32\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: relu, op_type: ReLU)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: maxpool, op_type: MaxPool2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer1_0_conv1, op_type: Conv2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace conv2d with in_channels: 32, out_channels: 32\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer1_0_bn1, op_type: BatchNorm2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace batchnorm2d with num_features: 32\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer1_0_relu, op_type: ReLU)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer1_0_conv2, op_type: Conv2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace conv2d with in_channels: 32, out_channels: 32\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer1_0_bn2, op_type: BatchNorm2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace batchnorm2d with num_features: 32\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer1_1_conv1, op_type: Conv2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace conv2d with in_channels: 32, out_channels: 32\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer1_1_bn1, op_type: BatchNorm2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace batchnorm2d with num_features: 32\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer1_1_relu, op_type: ReLU)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer1_1_conv2, op_type: Conv2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace conv2d with in_channels: 32, out_channels: 32\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer1_1_bn2, op_type: BatchNorm2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace batchnorm2d with num_features: 32\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer2_0_conv1, op_type: Conv2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace conv2d with in_channels: 32, out_channels: 64\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer2_0_bn1, op_type: BatchNorm2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace batchnorm2d with num_features: 64\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer2_0_relu, op_type: ReLU)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer2_0_conv2, op_type: Conv2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace conv2d with in_channels: 64, out_channels: 64\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer2_0_bn2, op_type: BatchNorm2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace batchnorm2d with num_features: 64\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer2_0_downsample_0, op_type: Conv2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace conv2d with in_channels: 32, out_channels: 64\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer2_0_downsample_1, op_type: BatchNorm2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace batchnorm2d with num_features: 64\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer2_1_conv1, op_type: Conv2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace conv2d with in_channels: 64, out_channels: 64\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer2_1_bn1, op_type: BatchNorm2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace batchnorm2d with num_features: 64\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer2_1_relu, op_type: ReLU)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer2_1_conv2, op_type: Conv2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace conv2d with in_channels: 64, out_channels: 64\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer2_1_bn2, op_type: BatchNorm2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace batchnorm2d with num_features: 64\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer3_0_conv1, op_type: Conv2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace conv2d with in_channels: 64, out_channels: 128\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer3_0_bn1, op_type: BatchNorm2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace batchnorm2d with num_features: 128\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer3_0_relu, op_type: ReLU)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer3_0_conv2, op_type: Conv2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace conv2d with in_channels: 128, out_channels: 128\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer3_0_bn2, op_type: BatchNorm2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace batchnorm2d with num_features: 128\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer3_0_downsample_0, op_type: Conv2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace conv2d with in_channels: 64, out_channels: 128\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer3_0_downsample_1, op_type: BatchNorm2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace batchnorm2d with num_features: 128\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer3_1_conv1, op_type: Conv2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace conv2d with in_channels: 128, out_channels: 128\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer3_1_bn1, op_type: BatchNorm2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace batchnorm2d with num_features: 128\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer3_1_relu, op_type: ReLU)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer3_1_conv2, op_type: Conv2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace conv2d with in_channels: 128, out_channels: 128\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer3_1_bn2, op_type: BatchNorm2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace batchnorm2d with num_features: 128\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer4_0_conv1, op_type: Conv2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace conv2d with in_channels: 128, out_channels: 256\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer4_0_bn1, op_type: BatchNorm2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace batchnorm2d with num_features: 256\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer4_0_relu, op_type: ReLU)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer4_0_conv2, op_type: Conv2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace conv2d with in_channels: 256, out_channels: 256\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer4_0_bn2, op_type: BatchNorm2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace batchnorm2d with num_features: 256\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer4_0_downsample_0, op_type: Conv2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace conv2d with in_channels: 128, out_channels: 256\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer4_0_downsample_1, op_type: BatchNorm2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace batchnorm2d with num_features: 256\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer4_1_conv1, op_type: Conv2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace conv2d with in_channels: 256, out_channels: 256\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer4_1_bn1, op_type: BatchNorm2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace batchnorm2d with num_features: 256\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer4_1_relu, op_type: ReLU)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer4_1_conv2, op_type: Conv2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace conv2d with in_channels: 256, out_channels: 256\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: layer4_1_bn2, op_type: BatchNorm2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace batchnorm2d with num_features: 256\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: avgpool, op_type: AdaptiveAvgPool2d)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace module (name: fc, op_type: Linear)\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mreplace linear with new in_features: 256, out_features: 10\u001b[0m\n",
      "[2024-09-23 17:38:36] \u001b[32mSpeedup done.\u001b[0m\n",
      "Compressed model paramater number:  2801450\n",
      "Compressed model without finetuning & qsim acc:  80.37 %\n"
     ]
    }
   ],
   "source": [
    "# speed up model\n",
    "masks = scheduled_pruner.get_masks()\n",
    "speedup = ModelSpeedup(model, dummy_input, masks)\n",
    "model = speedup.speedup_model()\n",
    "\n",
    "print('Compressed model paramater number: ', sum([param.numel() for param in model.parameters()]))\n",
    "print('Compressed model without finetuning & qsim acc: ', evaluate(model, test_loader), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取量化的校准配置，并使用 trans 函数调整配置，仿真量化过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate quantization\n",
    "calibration_config = quantizer.get_calibration_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans(calibration_config, speedup: ModelSpeedup):\n",
    "    for node, node_info in speedup.node_infos.items():\n",
    "        if node.op == 'call_module' and node.target in calibration_config:\n",
    "            # assume the module only has one input and one output\n",
    "            input_mask = speedup.node_infos[node.args[0]].output_masks\n",
    "            param_mask = node_info.param_masks\n",
    "            output_mask = node_info.output_masks\n",
    "\n",
    "            module_cali_config = calibration_config[node.target]\n",
    "            if '_input_0' in module_cali_config:\n",
    "                reduce_dims = list(range(len(input_mask.shape)))\n",
    "                reduce_dims.remove(1)\n",
    "                idxs = torch.nonzero(input_mask.sum(reduce_dims), as_tuple=True)[0].cpu()\n",
    "                module_cali_config['_input_0']['scale'] = module_cali_config['_input_0']['scale'].index_select(1, idxs)\n",
    "                module_cali_config['_input_0']['zero_point'] = module_cali_config['_input_0']['zero_point'].index_select(1, idxs)\n",
    "            if '_output_0' in module_cali_config:\n",
    "                reduce_dims = list(range(len(output_mask.shape)))\n",
    "                reduce_dims.remove(1)\n",
    "                idxs = torch.nonzero(output_mask.sum(reduce_dims), as_tuple=True)[0].cpu()\n",
    "                module_cali_config['_output_0']['scale'] = module_cali_config['_output_0']['scale'].index_select(1, idxs)\n",
    "                module_cali_config['_output_0']['zero_point'] = module_cali_config['_output_0']['zero_point'].index_select(1, idxs)\n",
    "            if 'weight' in module_cali_config:\n",
    "                reduce_dims = list(range(len(param_mask['weight'].shape)))\n",
    "                reduce_dims.remove(0)\n",
    "                idxs = torch.nonzero(param_mask['weight'].sum(reduce_dims), as_tuple=True)[0].cpu()\n",
    "                module_cali_config['weight']['scale'] = module_cali_config['weight']['scale'].index_select(0, idxs)\n",
    "                module_cali_config['weight']['zero_point'] = module_cali_config['weight']['zero_point'].index_select(0, idxs)\n",
    "            if 'bias' in module_cali_config:\n",
    "                idxs = torch.nonzero(param_mask['bias'], as_tuple=True)[0].cpu()\n",
    "                module_cali_config['bias']['scale'] = module_cali_config['bias']['scale'].index_select(0, idxs)\n",
    "                module_cali_config['bias']['zero_point'] = module_cali_config['bias']['zero_point'].index_select(0, idxs)\n",
    "    return calibration_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_config = trans(calibration_config, speedup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_quantizer = Quantizer(model, q_config_list)\n",
    "sim_quantizer.update_calibration_config(calibration_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed model paramater number:  2801450\n",
      "Compressed model without finetuning acc:  80.44 %\n"
     ]
    }
   ],
   "source": [
    "print('Compressed model paramater number: ', sum([param.numel() for param in model.parameters()]))\n",
    "print('Compressed model without finetuning acc: ', evaluate(model, test_loader), '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "distill",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
