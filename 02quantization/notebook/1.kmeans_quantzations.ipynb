{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kmeans 量化实践"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "聚类量化是利用K-means方法得到权重的聚类中心和标签。同时根据聚类中心和标签又可以回推到weight，当然过程中有损失。\n",
    "<div align=\"center\"> <img src=\"../images/k-means.png\"> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 环境配置\n",
    "\n",
    "首先，我们安装必须的环境，数据集和model使用和前几章相同的minist数据集和LeNet网络。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载用到的python库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6919dd3dd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "import math\n",
    "import random\n",
    "from collections import OrderedDict, defaultdict\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import *\n",
    "from torch.optim.lr_scheduler import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchprofile import profile_macs\n",
    "from torchvision.datasets import *\n",
    "from torchvision.transforms import *\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型和数据集\n",
    "\n",
    "数据集和模型的链接如下：\n",
    "\n",
    "- 模型权重：https://github.com/datawhalechina/awesome-compression/blob/main/docs/notebook/ch02/model.pt\n",
    "- 数据集：https://github.com/datawhalechina/awesome-compression/tree/main/docs/notebook/ch02/data/mnist/MNIST/raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个LeNet网络\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(in_features=16 * 4 * 4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(F.relu(self.conv1(x)))\n",
    "        x = self.maxpool(F.relu(self.conv2(x)))\n",
    "\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\") # 默认使用CPU\n",
    "model = LeNet().to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置归一化\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# 获取数据集\n",
    "data_dir = \"../../01prune/notebook/0.minist_classify\"\n",
    "train_dataset = datasets.MNIST(root=data_dir+'/data/mnist', train=True, download=True, transform=transform)  \n",
    "test_dataset = datasets.MNIST(root=data_dir+'/data/mnist', train=False, download=True, transform=transform)  # train=True训练集，=False测试集\n",
    "\n",
    "# 设置DataLoader\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1364/2689321200.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(data_dir+'/model.pt')\n"
     ]
    }
   ],
   "source": [
    "# 加载模型的状态字典\n",
    "checkpoint = torch.load(data_dir+'/model.pt')\n",
    "# 加载状态字典到模型\n",
    "model.load_state_dict(checkpoint)\n",
    "fp32_model = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建训练和验证函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "  model: nn.Module,\n",
    "  dataloader: DataLoader,\n",
    "  criterion: nn.Module,\n",
    "  optimizer: Optimizer,\n",
    "  scheduler: LambdaLR,\n",
    "  callbacks = None\n",
    ") -> None:\n",
    "  model.train()\n",
    "\n",
    "  for inputs, targets in tqdm(dataloader, desc='train', leave=False):\n",
    "    # Move the data from CPU to GPU\n",
    "    # inputs = inputs.to('mps')\n",
    "    # targets = targets.to('mps')\n",
    "\n",
    "    # Reset the gradients (from the last iteration)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward inference\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    # Backward propagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Update optimizer and LR scheduler\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    if callbacks is not None:\n",
    "        for callback in callbacks:\n",
    "            callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def evaluate(\n",
    "  model: nn.Module,\n",
    "  dataloader: DataLoader,\n",
    "  extra_preprocess = None\n",
    ") -> float:\n",
    "  model.eval()\n",
    "\n",
    "  num_samples = 0\n",
    "  num_correct = 0\n",
    "\n",
    "  for inputs, targets in tqdm(dataloader, desc=\"eval\", leave=False):\n",
    "    # Move the data from CPU to GPU\n",
    "    # inputs = inputs.to('mps')\n",
    "    if extra_preprocess is not None:\n",
    "        for preprocess in extra_preprocess:\n",
    "            inputs = preprocess(inputs)\n",
    "\n",
    "    # targets = targets.to('mps')\n",
    "\n",
    "    # Inference\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # Convert logits to class indices\n",
    "    outputs = outputs.argmax(dim=1)\n",
    "\n",
    "    # Update metrics\n",
    "    num_samples += targets.size(0)\n",
    "    num_correct += (outputs == targets).sum()\n",
    "\n",
    "  return (num_correct / num_samples * 100).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建两个函数：计算 Flops 和 Model Size\n",
    "\n",
    "- 参数量（ params ）：\n",
    "    参数的数量，通常以M为单位。\n",
    "    params = Kh × Kw × Cin × Cout\n",
    "- 模型大小(模型大小)：\n",
    "    在一般的深度学习的框架中（如 PyTorch ），一般是 32 位存储，即一个参数用 32 个 bit 来存储。所以，一个拥有 1M（这里的M是数量单位一百万）参数量的模型所需要的存储空间大小为：1M * 32bit = 32Mb = 4MB。\n",
    "- 计算量( Flops )：\n",
    "\n",
    "    即浮点运算数，用来衡量算法/模型的复杂度。图通常只考虑乘加操作的数量，而且只考虑Conv和FC等参数层计算量，忽略BN和PReLU等。一般情况下，Conv和FC层也会忽略仅纯加操作的计算量，如偏置加和shortcut残差加等。目前技术只有BN和CNN可以不加偏置。\n",
    "    FLOPs = Kh * Kw * Cin * Cout * H * W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_flops(model, inputs):\n",
    "    num_macs = profile_macs(model, inputs)\n",
    "    return num_macs\n",
    "\n",
    "def get_model_size(model: nn.Module, data_width=32):\n",
    "    \"\"\"\n",
    "    calculate the model size in bits\n",
    "    :param data_width: #bits per element\n",
    "    \"\"\"\n",
    "    num_elements = 0\n",
    "    for param in model.parameters():\n",
    "        num_elements += param.numel()\n",
    "    return num_elements * data_width\n",
    "\n",
    "Byte = 8\n",
    "KiB = 1024 * Byte\n",
    "MiB = 1024 * KiB\n",
    "GiB = 1024 * MiB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证 FP32 模型的精度以及模型大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d2009e77a54cf5adda837979cc1e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp32 model has accuracy=97.99%\n",
      "fp32 model has size=0.17 MiB\n"
     ]
    }
   ],
   "source": [
    "fp32_model_accuracy = evaluate(fp32_model, test_loader)\n",
    "fp32_model_size = get_model_size(fp32_model)\n",
    "print(f\"fp32 model has accuracy={fp32_model_accuracy:.2f}%\")\n",
    "print(f\"fp32 model has size={fp32_model_size/MiB:.2f} MiB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建 K-means 量化函数\n",
    "\n",
    "$n$比特的k-means量化将把数据划分为$2^n$个聚类，而相同聚类中的数据将共享相同的权重值。\n",
    "\n",
    "k-means量化将创建一个 codebook ，其中包括：\n",
    "\n",
    "- centroids：$2^n$ 个FP32聚类中心。\n",
    "- labels：一个$n$比特的整数张量，与原始的FP32权重张量具有相同的元素数量。每个整数表示它属于哪个聚类。\n",
    "\n",
    "在推理期间，基于 codebook 生成一个 FP32 张量进行推理：\n",
    "> ***quantized_weight* = *codebook.centroids*\\[*codebook.labels*\\].view_as(weight)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    target bitwidth: 2 bits\n",
      "        num unique values before k-means quantization: 15\n",
      "        num unique values after  k-means quantization: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fast_pytorch_kmeans import KMeans\n",
    "from collections import namedtuple\n",
    "import pdb\n",
    "Codebook = namedtuple('Codebook', ['centroids', 'labels'])\n",
    "def k_means_quantize(fp32_tensor: torch.Tensor, bitwidth=4, codebook=None):\n",
    "    \"\"\"\n",
    "    quantize tensor using k-means clustering\n",
    "    :param fp32_tensor:\n",
    "    :param bitwidth: [int] quantization bit width, default=4\n",
    "    :param codebook: [Codebook] (the cluster centroids, the cluster label tensor)\n",
    "    :return:\n",
    "        [Codebook = (centroids, labels)]\n",
    "            centroids: [torch.(cuda.)FloatTensor] the cluster centroids\n",
    "            labels: [torch.(cuda.)LongTensor] cluster label tensor\n",
    "    \"\"\"\n",
    "    if codebook is None:\n",
    "        # 首先计算聚类的中心点个数\n",
    "        # get number of clusters based on the quantization precision\n",
    "        n_clusters = 2**bitwidth\n",
    "        # print(n_clusters)\n",
    "        # 用kmeans算法得到聚类的中心\n",
    "        # use k-means to get the quantization centroids\n",
    "        kmeans = KMeans(n_clusters=n_clusters, mode='euclidean', verbose=0)\n",
    "        labels = kmeans.fit_predict(fp32_tensor.view(-1, 1)).to(torch.long)\n",
    "        centroids = kmeans.centroids.to(torch.float).view(-1)\n",
    "        codebook = Codebook(centroids, labels)\n",
    "    \n",
    "    # decode the codebook into k-means quantized tensor for inference\n",
    "    # 解码codebook，得到k-means量化后的tensor\n",
    "    quantized_tensor = codebook.centroids[codebook.labels]\n",
    "    \n",
    "    fp32_tensor.set_(quantized_tensor.view_as(fp32_tensor))\n",
    "    return codebook\n",
    "\n",
    "def plot_matrix(tensor, ax, title, cmap=ListedColormap(['white'])):\n",
    "    ax.imshow(tensor.cpu().numpy(), vmin=-0.5, vmax=0.5, cmap=cmap)\n",
    "    ax.set_title(title)\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    for i in range(0,tensor.shape[0]):\n",
    "        for j in range(0,tensor.shape[1]):\n",
    "            \n",
    "            text = ax.text(j, i, f'{tensor[i, j].item():.2f}',ha=\"center\", va=\"center\", color=\"k\") \n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    bitwidth = 2\n",
    "    test_tensor = torch.tensor([\n",
    "        [-0.3747,  0.0874,  0.3200, -0.4868,  0.4404],\n",
    "        [-0.0402,  0.2322, -0.2024, -0.4986,  0.1814],\n",
    "        [ 0.3102, -0.3942, -0.2030,  0.0883, -0.4741]])\n",
    "    \n",
    "    fig, axes = plt.subplots(1,2, figsize=(8, 12))\n",
    "    ax_left, ax_right = axes.ravel()\n",
    "    \n",
    "    plot_matrix(test_tensor, ax_left, 'original tensor')\n",
    "    \n",
    "    num_unique_values_before_quantization = test_tensor.unique().numel()\n",
    "\n",
    "    codebook_test = k_means_quantize(fp32_tensor=test_tensor, bitwidth=bitwidth)\n",
    "    # pdb.set_trace()\n",
    "    num_unique_values_after_quantization = test_tensor.unique().numel()\n",
    "    \n",
    "    print(f'    target bitwidth: {bitwidth} bits')\n",
    "    print(f'        num unique values before k-means quantization: {num_unique_values_before_quantization}')\n",
    "    print(f'        num unique values after  k-means quantization: {num_unique_values_after_quantization}')\n",
    "    assert num_unique_values_after_quantization == min((1 << bitwidth), num_unique_values_before_quantization)\n",
    "    \n",
    "    plot_matrix(test_tensor, ax_right, f'{bitwidth}-bit k-means quantized tensor', \\\n",
    "                    cmap='tab20c')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在FP32模型上进行K-means量化\n",
    "\n",
    "在下边代码中构建的类`KMeansQuantizer`中，我们必须记录`centroids`和`labels`，以便在模型权重改变时应用或更新 `codebooks`。\n",
    "    \n",
    "``````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import parameter\n",
    "class KMeansQuantizer:\n",
    "    def __init__(self, model : nn.Module, bitwidth=4):\n",
    "        self.codebook = self.quantize(model, bitwidth)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def apply(self, model, update_centroids):\n",
    "        for name, param in model.named_parameters():\n",
    "            if name in self.codebook:\n",
    "                if update_centroids:\n",
    "                    self.update_codebook(param, codebook=self.codebook[name])\n",
    "                self.codebook[name] = k_means_quantize(\n",
    "                    param, codebook=self.codebook[name])\n",
    "                \n",
    "    def update_codebook(self,fp32_tensor: torch.Tensor, codebook: Codebook):\n",
    "        \"\"\"\n",
    "        update the centroids in the codebook using updated fp32_tensor\n",
    "        :param fp32_tensor: [torch.(cuda.)Tensor]\n",
    "        :param codebook: [Codebook] (the cluster centroids, the cluster label tensor)\n",
    "        \"\"\"\n",
    "        n_clusters = codebook.centroids.numel()\n",
    "        fp32_tensor = fp32_tensor.view(-1)\n",
    "        for k in range(n_clusters):\n",
    "            cluster_points = fp32_tensor[codebook.labels == k]\n",
    "            if cluster_points.numel() > 0:\n",
    "                codebook.centroids[k] = cluster_points.mean()\n",
    "                \n",
    "    @staticmethod\n",
    "    @torch.no_grad()\n",
    "    def quantize(model: nn.Module, bitwidth=4):\n",
    "        codebook = dict()\n",
    "        if isinstance(bitwidth, dict):\n",
    "            for name, param in model.named_parameters():\n",
    "                if name in bitwidth:\n",
    "                    codebook[name] = k_means_quantize(param, bitwidth=bitwidth[name])\n",
    "        else:\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.dim() > 1:\n",
    "                    codebook[name] = k_means_quantize(param, bitwidth=bitwidth)\n",
    "        return codebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们看一下不同的bitwidth下，模型量化后的精度和大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note that the storage for codebooks is ignored when calculating the model size.\n",
      "k-means quantizing model into 8 bits\n",
      "    8-bit k-means quantized model has size=0.04 MiB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b73db5a84c284310b2b17d410cef41ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    8-bit k-means quantized model has accuracy=97.84%\n",
      "k-means quantizing model into 4 bits\n",
      "    4-bit k-means quantized model has size=0.02 MiB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068b5f0879714f83b940539a889113f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    4-bit k-means quantized model has accuracy=97.03%\n",
      "k-means quantizing model into 2 bits\n",
      "    2-bit k-means quantized model has size=0.01 MiB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f316c45ed0fa463cb2d9b8c3fdf5ed04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2-bit k-means quantized model has accuracy=89.44%\n"
     ]
    }
   ],
   "source": [
    "print('Note that the storage for codebooks is ignored when calculating the model size.')\n",
    "quantizers = dict()\n",
    "for bitwidth in [8, 4, 2]:\n",
    "    print(f'k-means quantizing model into {bitwidth} bits')\n",
    "    quantizer = KMeansQuantizer(model, bitwidth)\n",
    "    quantized_model_size = get_model_size(model, bitwidth)\n",
    "    print(f\"    {bitwidth}-bit k-means quantized model has size={quantized_model_size/MiB:.2f} MiB\")\n",
    "    quantized_model_accuracy = evaluate(model, test_loader)\n",
    "    print(f\"    {bitwidth}-bit k-means quantized model has accuracy={quantized_model_accuracy:.2f}%\")\n",
    "    quantizers[bitwidth] = quantizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练 kmeans 量化模型\n",
    "可以看到上一步中量化后的模型精度大幅下降，因此我们必须执行量化感知训练来恢复精度。\n",
    "\n",
    "centroids的梯度更新公式如下：\n",
    "\n",
    "> $\\frac{\\partial \\mathcal{L} }{\\partial C_k} = \\sum_{j} \\frac{\\partial \\mathcal{L} }{\\partial W_{j}} \\frac{\\partial W_{j} }{\\partial C_k} = \\sum_{j} \\frac{\\partial \\mathcal{L} }{\\partial W_{j}} \\mathbf{1}(I_{j}=k)$\n",
    "\n",
    " $\\mathcal{L}$ 是损失, $C_k$ 是第 *k* 个 centroids , $I_{j}$ 是权重 $W_{j}$ 的 label 。$\\mathbf{1}()$ 是找对应 label 的函数, 即, $I_{j}==k$.\n",
    "\n",
    "我们用如下公式更新centroids：\n",
    "\n",
    "> $C_k = \\frac{\\sum_{j}W_{j}\\mathbf{1}(I_{j}=k)}{\\sum_{j}\\mathbf{1}(I_{j}=k)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-means quantizing model into 8 bits\n",
      "    8-bit k-means quantized model has size=0.04 MiB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc608a73cdbb460ea8bc93e68e4191e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    8-bit k-means quantized model has accuracy=97.84% before quantization-aware training \n",
      "        No need for quantization-aware training since accuracy drop=0.15% is smaller than threshold=0.50%\n",
      "k-means quantizing model into 4 bits\n",
      "    4-bit k-means quantized model has size=0.02 MiB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd27336167d48dd829fb6ad3a79aa2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    4-bit k-means quantized model has accuracy=97.03% before quantization-aware training \n",
      "        Quantization-aware training due to accuracy drop=0.96% is larger than threshold=0.50%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e685059c9b564848892494f72466702c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd19b2190cd47c9bc9e33c962bf8826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 0 Accuracy 97.85% / Best Accuracy: 97.85%\n",
      "k-means quantizing model into 2 bits\n",
      "    2-bit k-means quantized model has size=0.01 MiB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b090232cf8f7425ba59237a70d7b7644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2-bit k-means quantized model has accuracy=90.54% before quantization-aware training \n",
      "        Quantization-aware training due to accuracy drop=7.45% is larger than threshold=0.50%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5935dc552a440229519eae359685657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d7ad678fe34f778831760a95a4a3f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 0 Accuracy 95.98% / Best Accuracy: 95.98%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2274119e34c94b20b7ee6d7c019f083c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7c28ea16fa48d8bb3dce2f1434420f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 1 Accuracy 96.48% / Best Accuracy: 96.48%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4234dbf7e54d5ba0b44c2e6db45185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9385eb2dce264eaebe6876c715f589bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 2 Accuracy 96.63% / Best Accuracy: 96.63%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13637d70cdd4633a2c18c0a9029a5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9625f64e6e9a4bd2b47c7e5348efc655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 3 Accuracy 96.66% / Best Accuracy: 96.66%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d566add4fe8643559f6cb543e5add0ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a71acdfbe9d4b8da6d495e1cc07bf1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 4 Accuracy 96.73% / Best Accuracy: 96.73%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8031cef8644462ad44c851c8709a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0537de99261346189c51f625e56146ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 5 Accuracy 96.68% / Best Accuracy: 96.73%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20c32654a7a43d6851e52034316ac71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea3f328127f4940af61858562e4a543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 6 Accuracy 96.93% / Best Accuracy: 96.93%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea4d30dece94945a88b246b7c95a872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff2696b967548aca426d5961f47587a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 7 Accuracy 96.80% / Best Accuracy: 96.93%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62a4d7a293e4addb983a3cd3a403276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23c35f8ee144edfa832101ccd038233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 8 Accuracy 96.99% / Best Accuracy: 96.99%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7fc92711ff1400db2c10d26137be200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3857c630bc8941beab352f0f16ac1f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch 9 Accuracy 97.07% / Best Accuracy: 97.07%\n"
     ]
    }
   ],
   "source": [
    "accuracy_drop_threshold = 0.5\n",
    "quantizers_before_finetune = copy.deepcopy(quantizers)\n",
    "quantizers_after_finetune = quantizers\n",
    "\n",
    "for bitwidth in [8, 4, 2]:\n",
    "    quantizer = quantizers[bitwidth]\n",
    "    print(f'k-means quantizing model into {bitwidth} bits')\n",
    "    quantizer.apply(model, update_centroids=False)\n",
    "    quantized_model_size = get_model_size(model, bitwidth)\n",
    "    print(f\"    {bitwidth}-bit k-means quantized model has size={quantized_model_size/MiB:.2f} MiB\")\n",
    "    quantized_model_accuracy = evaluate(model, test_loader)\n",
    "    print(f\"    {bitwidth}-bit k-means quantized model has accuracy={quantized_model_accuracy:.2f}% before quantization-aware training \")\n",
    "    accuracy_drop = fp32_model_accuracy - quantized_model_accuracy\n",
    "    if accuracy_drop > accuracy_drop_threshold:\n",
    "        print(f\"        Quantization-aware training due to accuracy drop={accuracy_drop:.2f}% is larger than threshold={accuracy_drop_threshold:.2f}%\")\n",
    "        num_finetune_epochs = 10\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_finetune_epochs)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        best_accuracy = 0\n",
    "        epoch = num_finetune_epochs\n",
    "        while accuracy_drop > accuracy_drop_threshold and epoch > 0:\n",
    "            train(model, train_loader, criterion, optimizer, scheduler,\n",
    "                  callbacks=[lambda: quantizer.apply(model, update_centroids=True)])\n",
    "            model_accuracy = evaluate(model, test_loader)\n",
    "            is_best = model_accuracy > best_accuracy\n",
    "            best_accuracy = max(model_accuracy, best_accuracy)\n",
    "            print(f'        Epoch {num_finetune_epochs-epoch} Accuracy {model_accuracy:.2f}% / Best Accuracy: {best_accuracy:.2f}%')\n",
    "            accuracy_drop = fp32_model_accuracy - best_accuracy\n",
    "            epoch -= 1\n",
    "    else:\n",
    "        print(f\"        No need for quantization-aware training since accuracy drop={accuracy_drop:.2f}% is smaller than threshold={accuracy_drop_threshold:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
