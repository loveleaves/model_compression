{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 知识蒸馏\n",
    "\n",
    "在trainStudent中，我们直接使用简单的网络进行训练，当epoch为5时，模型准确率为58.66%，在本节中，我们使用知识蒸馏训练简单网络来对比使用知识蒸馏前后的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "# 知识蒸馏 KD 的损失函数\n",
    "from loss.kd import loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机数种子, 从而可以复现\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "setup_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = (\n",
    "#     \"cuda\"\n",
    "#     if torch.cuda.is_available()\n",
    "#     else \"mps\"\n",
    "#     if torch.backends.mps.is_available()\n",
    "#     else \"cpu\"\n",
    "# )\n",
    "\n",
    "device = \"cuda\" # 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 4               # temperature : 知识蒸馏中的温度\n",
    "ALPHA = 0.1         # alpha : hard_loss(硬损失交叉熵)的loss weight \n",
    "BETA = 0.9          # beta : soft_loss(软损失KL散度)的loss weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载教师模型, 以及定义学生网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4359/2986061969.py:42: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  teacher_net.load_state_dict(torch.load(data_dir+'/model.pt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(in_features=16 * 4 * 4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(F.relu(self.conv1(x)))\n",
    "        x = self.maxpool(F.relu(self.conv2(x)))\n",
    "\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class LeNetHalfChannel(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNetHalfChannel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=5)   \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(in_features=3 * 12 * 12, out_features=num_classes)   \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(F.relu(self.conv1(x)))\n",
    "\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "teacher_net = LeNet().to(device=device)\n",
    "student_net = LeNetHalfChannel().to(device=device)\n",
    "\n",
    "data_dir = \"../../01prune/notebook/0.minist_classify\"\n",
    "teacher_net.load_state_dict(torch.load(data_dir+'/model.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据集\n",
    "第一次使用会先进行下载, 如果下载的很慢, 可以手动下载数据集然后拖入到 data 文件夹下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置归一化\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# 获取数据集\n",
    "# 这里直接读取 ch02 中下载好的数据\n",
    "train_dataset = datasets.MNIST(root=data_dir+'/data/mnist/', train=True, download=False, transform=transform)  \n",
    "test_dataset = datasets.MNIST(root=data_dir+'/data/mnist/', train=False, download=False, transform=transform)  # train=True训练集，=False测试集\n",
    "\n",
    "# 设置DataLoader\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "num_epoch = 5\n",
    "optimizer = torch.optim.SGD(student_net.parameters(),  lr=lr, momentum=momentum)  # lr学习率，momentum冲量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train函数和Test函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分别定义训练集和测试集上的最佳Acc, 使用 global 修饰为全局变量, 然后再训练期间更新\n",
    "best_train_acc = 0\n",
    "best_test_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(epoch):\n",
    "    global best_train_acc\n",
    "\n",
    "    # 设置学生模型为训练模式\n",
    "    student_net.train()\n",
    "\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # 使用 tqdm 包装 trainloader 以显示进度条\n",
    "    with tqdm(train_loader, desc=f\"Training Epoch {epoch}\", total=len(train_loader)) as pbar:\n",
    "        for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits_student = student_net(inputs)\n",
    "            with torch.no_grad():\n",
    "                logits_teacher = teacher_net(inputs)\n",
    "\n",
    "            # 硬损失\n",
    "            ce_loss = nn.CrossEntropyLoss()(logits_student, targets)\n",
    "            # 软损失\n",
    "            kd_loss = loss(logits_student, logits_teacher, temperature=T)\n",
    "            total_loss = ALPHA * ce_loss + BETA * kd_loss\n",
    "\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += total_loss.item()\n",
    "            _, predicted = logits_student.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            # 使用 set_postfix 更新进度条的后缀\n",
    "            pbar.set_postfix(loss=train_loss / (batch_idx + 1), acc=f\"{100. * correct / total:.1f}%\")\n",
    "\n",
    "    # 如果当前训练集上的准确率高于 best_test_acc，则更新 best_test_acc\n",
    "    acc = 100 * correct / total\n",
    "    if acc > best_train_acc:\n",
    "        best_train_acc = acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, epoch):\n",
    "    global best_test_acc\n",
    "    net.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 使用 tqdm 包装 testloader 以显示进度条\n",
    "        with tqdm(test_loader, desc=f\"Testing Epoch {epoch}\", total=len(test_loader)) as pbar:\n",
    "            for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                logits_student = net(inputs)\n",
    "\n",
    "                loss = nn.CrossEntropyLoss()(logits_student, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = logits_student.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "                # 在 tqdm 进度条的后缀中显示当前损失和准确率\n",
    "                pbar.set_postfix(loss=test_loss / (batch_idx + 1), acc=f\"{100. * correct / total:.1f}%\")\n",
    "\n",
    "        # 计算当前测试集上的准确率\n",
    "        acc = 100. * correct / total\n",
    "\n",
    "        # 如果当前测试集上的准确率高于 best_test_acc，则更新 best_test_acc\n",
    "        # 并且将学生模型保存下来\n",
    "        if acc > best_test_acc:\n",
    "            print('Saving..')\n",
    "            torch.save(student_net, 'checkpoints/distillation_kd.pt')\n",
    "            best_test_acc = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|█████████████████████████████████████████| 938/938 [00:18<00:00, 50.97it/s, acc=75.1%, loss=5.23]\n",
      "Testing Epoch 1: 100%|█████████████████████████████████████████| 157/157 [00:02<00:00, 67.40it/s, acc=79.8%, loss=0.789]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|█████████████████████████████████████████| 938/938 [00:18<00:00, 51.74it/s, acc=80.7%, loss=4.32]\n",
      "Testing Epoch 2: 100%|█████████████████████████████████████████| 157/157 [00:02<00:00, 67.98it/s, acc=81.5%, loss=0.685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|█████████████████████████████████████████| 938/938 [00:18<00:00, 51.65it/s, acc=82.4%, loss=4.05]\n",
      "Testing Epoch 3: 100%|█████████████████████████████████████████| 157/157 [00:02<00:00, 60.45it/s, acc=86.1%, loss=0.416]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|█████████████████████████████████████████| 938/938 [00:18<00:00, 51.54it/s, acc=86.4%, loss=2.23]\n",
      "Testing Epoch 4: 100%|█████████████████████████████████████████| 157/157 [00:02<00:00, 64.38it/s, acc=86.8%, loss=0.376]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|█████████████████████████████████████████| 938/938 [00:18<00:00, 51.32it/s, acc=86.7%, loss=2.14]\n",
      "Testing Epoch 5: 100%|█████████████████████████████████████████| 157/157 [00:02<00:00, 62.24it/s, acc=87.0%, loss=0.357]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epoch + 1) :\n",
    "    train(epoch)\n",
    "    test(student_net, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_Train_Acc =  86.695\n",
      "best_Test_Acc =  87.03\n"
     ]
    }
   ],
   "source": [
    "print('best_Train_Acc = ', best_train_acc)\n",
    "print('best_Test_Acc = ', best_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接训练学生模型准确率为58.66%；使用知识蒸馏的方式训练学生模型，测试集上的准确率为96.85%。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
