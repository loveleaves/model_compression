{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用DKD方式进行蒸馏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现有的知识蒸馏方法主要关注于中间层的深度特征蒸馏，而对logit蒸馏的重要性认识不足。[DKD]()重新定义了传统的知识蒸馏损失函数，将其分解为目标类知识蒸馏（TCKD）和非目标类知识蒸馏（NCKD）。\n",
    "- 目标类知识蒸馏（TCKD）：关注于目标类的知识传递。\n",
    "- 非目标类知识蒸馏（NCKD）：关注于非目标类之间的知识传递。\n",
    "\n",
    "![DKD](../images/dkd.png)\n",
    "\n",
    "传统的知识蒸馏损失函数可以表示为:\n",
    "\n",
    "$$\n",
    "K D=K L\\left(p_T \\| p_S\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "其中， $p_T$ 和 $p_S$ 分别是教师模型和学生模型的预测概率。\n",
    "在DKD中，损失函数被重构为:\n",
    "\n",
    "$$\n",
    "K D=T C K D+\\left(1-p_T^t\\right) \\cdot N C K D\n",
    "$$\n",
    "\n",
    "\n",
    "这里， $p_T^t$ 是教师模型对目标类的预测概率。\n",
    "\n",
    "\n",
    "\n",
    "在DKD中，引入了两个超参数：\n",
    "- $\\alpha$ ：用于TCKD的权重。\n",
    "- $\\boldsymbol{\\beta}$ ：用于NCKD的权重。\n",
    "\n",
    "因此，DKD的损失函数可以表示为:\n",
    "\n",
    "$$\n",
    "D K D=\\alpha \\cdot T C K D+\\beta \\cdot N C K D\n",
    "$$\n",
    "\n",
    "\n",
    "通过调整这两个超参数，可以灵活地平衡TCKD和NCKD的重要性。\n",
    "\n",
    "\n",
    "在训练过程中，DKD的实现步骤如下:\n",
    "1. 计算logits: 从教师模型和学生模型中获取输出logits。\n",
    "2. 应用softmax: 将logits转换为概率分布。\n",
    "3. 计算 $T C K D$ 和NCKD:\n",
    "   - TCKD: 计算教师和学生在目标类上的KL散度。\n",
    "   - NCKD：计算教师和学生在非目标类上的KL散度。\n",
    "4. 合并损失：根据超参数 $\\alpha$ 和 $\\beta$ 合并TCKD和NCKD的损失，得到最终的DKD损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "# 知识蒸馏 KD 的损失函数\n",
    "from loss.dkd import dkd_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机数种子, 从而可以复现\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "setup_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = (\n",
    "#     \"cuda\"\n",
    "#     if torch.cuda.is_available()\n",
    "#     else \"mps\"\n",
    "#     if torch.backends.mps.is_available()\n",
    "#     else \"cpu\"\n",
    "# )\n",
    "device = \"cuda\" # cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 4               # temperature : 知识蒸馏中的温度\n",
    "ALPHA = 1.0         # alpha : TCKD 部分的loss weight\n",
    "BETA = 2.0          # beta : NCKD 部分的loss weight\n",
    "LOSS_CE = 1.0       # loss_ce : 交叉熵的loss weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载教师模型, 以及定义学生网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4567/4176293771.py:42: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  teacher_net.load_state_dict(torch.load(data_dir+'/model.pt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(in_features=16 * 4 * 4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(F.relu(self.conv1(x)))\n",
    "        x = self.maxpool(F.relu(self.conv2(x)))\n",
    "\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class LeNetHalfChannel(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNetHalfChannel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=5)   \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(in_features=3 * 12 * 12, out_features=10)   \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(F.relu(self.conv1(x)))\n",
    "\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "teacher_net = LeNet().to(device=device)\n",
    "student_net = LeNetHalfChannel().to(device=device)\n",
    "\n",
    "data_dir = \"../../01prune/notebook/0.minist_classify\"\n",
    "teacher_net.load_state_dict(torch.load(data_dir+'/model.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置归一化\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# 获取数据集\n",
    "# 这里直接读取 ch02 中下载好的数据\n",
    "train_dataset = datasets.MNIST(root=data_dir+'/data/mnist/', train=True, download=False, transform=transform)  \n",
    "test_dataset = datasets.MNIST(root=data_dir+'/data/mnist/', train=False, download=False, transform=transform)  # train=True训练集，=False测试集\n",
    "\n",
    "# 设置DataLoader\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "num_epoch = 5\n",
    "optimizer = torch.optim.SGD(student_net.parameters(),  lr=lr, momentum=momentum)  # lr学习率，momentum冲量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train函数和Test函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分别定义训练集和测试集上的最佳Acc, 使用 global 修饰为全局变量, 然后再训练期间更新\n",
    "best_train_acc = 0\n",
    "best_test_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(epoch):\n",
    "    global best_train_acc\n",
    "\n",
    "    # 设置学生模型为训练模式\n",
    "    student_net.train()\n",
    "\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # 使用 tqdm 包装 trainloader 以显示进度条\n",
    "    with tqdm(train_loader, desc=f\"Training Epoch {epoch}\", total=len(train_loader)) as pbar:\n",
    "        for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits_student = student_net(inputs)\n",
    "            with torch.no_grad():\n",
    "                logits_teacher = teacher_net(inputs)\n",
    "\n",
    "            # 硬损失\n",
    "            ce_loss = nn.CrossEntropyLoss()(logits_student, targets)\n",
    "            # 软损失\n",
    "            kd_loss = dkd_loss(logits_student, logits_teacher, targets, ALPHA, BETA, T)\n",
    "            total_loss = ALPHA * ce_loss + BETA * kd_loss\n",
    "\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += total_loss.item()\n",
    "            _, predicted = logits_student.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            # 使用 set_postfix 更新进度条的后缀\n",
    "            pbar.set_postfix(loss=train_loss / (batch_idx + 1), acc=f\"{100. * correct / total:.1f}%\")\n",
    "\n",
    "    # 如果当前训练集上的准确率高于 best_test_acc，则更新 best_test_acc\n",
    "    acc = 100 * correct / total\n",
    "    if acc > best_train_acc:\n",
    "        best_train_acc = acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, epoch):\n",
    "    global best_test_acc\n",
    "    net.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 使用 tqdm 包装 testloader 以显示进度条\n",
    "        with tqdm(test_loader, desc=f\"Testing Epoch {epoch}\", total=len(test_loader)) as pbar:\n",
    "            for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                logits_student = net(inputs)\n",
    "\n",
    "                loss = nn.CrossEntropyLoss()(logits_student, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = logits_student.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "                # 在 tqdm 进度条的后缀中显示当前损失和准确率\n",
    "                pbar.set_postfix(loss=test_loss / (batch_idx + 1), acc=f\"{100. * correct / total:.1f}%\")\n",
    "\n",
    "        # 计算当前测试集上的准确率\n",
    "        acc = 100. * correct / total\n",
    "\n",
    "        # 如果当前测试集上的准确率高于 best_test_acc，则更新 best_test_acc\n",
    "        # 并且将学生模型保存下来\n",
    "        if acc > best_test_acc:\n",
    "            print('Saving..')\n",
    "            torch.save(student_net, 'checkpoints/distillation_dkd.pt')\n",
    "            best_test_acc = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tony/miniconda3/envs/pt11.8/lib/python3.10/site-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Training Epoch 1: 100%|█████████████████████████████████████████| 938/938 [00:17<00:00, 52.51it/s, acc=47.9%, loss=34.6]\n",
      "Testing Epoch 1: 100%|███████████████████████████████████████████| 157/157 [00:02<00:00, 69.17it/s, acc=50.3%, loss=1.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|█████████████████████████████████████████| 938/938 [00:17<00:00, 54.71it/s, acc=55.7%, loss=30.6]\n",
      "Testing Epoch 2: 100%|██████████████████████████████████████████| 157/157 [00:02<00:00, 71.65it/s, acc=59.0%, loss=1.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|█████████████████████████████████████████| 938/938 [00:17<00:00, 54.13it/s, acc=58.9%, loss=29.3]\n",
      "Testing Epoch 3: 100%|██████████████████████████████████████████| 157/157 [00:02<00:00, 74.74it/s, acc=59.2%, loss=1.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|█████████████████████████████████████████| 938/938 [00:17<00:00, 55.02it/s, acc=58.9%, loss=29.2]\n",
      "Testing Epoch 4: 100%|██████████████████████████████████████████| 157/157 [00:02<00:00, 74.88it/s, acc=59.1%, loss=1.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|█████████████████████████████████████████| 938/938 [00:16<00:00, 57.67it/s, acc=58.9%, loss=29.2]\n",
      "Testing Epoch 5: 100%|███████████████████████████████████████████| 157/157 [00:02<00:00, 74.99it/s, acc=59.1%, loss=1.3]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epoch + 1) :\n",
    "    train(epoch)\n",
    "    test(student_net, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_Train_Acc =  58.915\n",
      "best_Test_Acc =  59.17\n"
     ]
    }
   ],
   "source": [
    "print('best_Train_Acc = ', best_train_acc)\n",
    "print('best_Test_Acc = ', best_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
